{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce78432d",
   "metadata": {},
   "source": [
    "<center><img src=\"WHU.png\" alt=\"武汉大学校徽\"/></center>\n",
    "<center><font size=\"7\">实验报告</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab4a588",
   "metadata": {},
   "source": [
    "# 神经网络可视化实验\n",
    "专业: 临床医学(八年制)  \n",
    "班级: 3班  \n",
    "姓名: 闻人星湘  \n",
    "指导教师: 王翀  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c264c56a",
   "metadata": {},
   "source": [
    "## 实验环境说明\n",
    "本地实验的配置信息如下:\n",
    "1. 该实验所使用的操作系统为 Ubuntu 24.04 LTS, CPU 为 AMD RYZEN 5000 Series 7, GPU 为 Geforce RTX 3050.\n",
    "2. 该实验使用的 Python 版本为 3.12.3, CUDA Toolkit 版本为 12.4, cuDNN 版本为 9.8, [Pytorch](https://pytorch.org/) 版本为 2.6.\n",
    "\n",
    "云端实验的配置信息如下:  \n",
    "&emsp;&emsp;该实验所使用的浏览器为 Firefox, 浏览器中使用 [TensorFlow Playground](https://playground.tensorflow.org/) 进行探究."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d549af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用cuda训练模型.\n"
     ]
    }
   ],
   "source": [
    "# 导入需要的第三方库\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "# 根据实际情况选择训练硬件\n",
    "device = torch.accelerator.current_accelerator().type \\\n",
    "    if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"使用{device}训练模型.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ae7481",
   "metadata": {},
   "source": [
    "\n",
    "## 实验目标\n",
    "1. 理解神经网络的基本结构: 了解神经网络的层(Layer), 包括输入层(Iuput Layer), 隐藏层(Hidden Layer), 输出层(Output Layer); 了解神经网络的激活函数(Activation Function), 包括但不限于线性整流函数(ReLU), 双曲正弦函数(Tanh), S型函数(Sigmoid), 归一化指数函数(Softmax)等. 学会合理配置神经网络层数以及每层神经元数.\n",
    "2. 观察神经网络的训练过程: 了解损失函数(Loss Function), 参数更新策略(Parameter Update Strategy), 学习率(Learning Rate), 前向传播(Forward), 反向传播(Backward), 批大小(Batch Size), 训练轮数(Epoch)的概念, 学会通过损失曲线(Loss Curve)判断网络是否在学习.\n",
    "3. 掌握神经网络的超参数调优: 学会调整 Learning rate, 理解它对训练速度的影响; 尝试不同激活函数, 观察分类效果的变化; 了解正则化(Regularization)以及如何防止模型过拟合.\n",
    "4. 理解神经网络能解决的问题类型: 通过不同数据集(如圆形分布, 螺旋分布等)，理解神经网络如何分类复杂数据, 学会通过添加特征(如$X^2$​, $\\sin(x)$等​)提升模型性能.\n",
    "5. 培养动手实践和问题解决能力: 通过调整参数和结构，完成分类任务挑战; 学会分析实验结果，提出改进方案."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c856bee5",
   "metadata": {},
   "source": [
    "## 实验具体内容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec82ed1",
   "metadata": {},
   "source": [
    "### 初识神经网络\n",
    "实验设置: 使用圆形分布数据集, 设置学习率为 0.03, 激活函数为 Tanh, 隐藏层为 1 层 4 个神经元.  \n",
    "实验结果如下:\n",
    "<img src=\"First.png\" alt=\"初识神经网络\">\n",
    "\n",
    "&emsp;&emsp;可以观察到, 背景颜色原本为无色(还未开始训练), 而后迅速变为橙色包裹蓝色, 蓝色朝某个方向开口, 随着训练时间增加, 蓝色迅速闭合. 分类前后明显可以在背景颜色和数据点(Sample)的位置关系看到差异: 训练结束后数据点和背景对应得很好.  \n",
    "&emsp;&emsp;损失曲线均呈S型, 初期和末期下降速度慢, 中期下降较快. 训练结束后训练数据上的损失和测试数据上的损失差异很小(0.01)且均较低, 表明模型有良好的泛化能力, 但是数据集和模型非常简单(没有噪声的引入, 隐藏层数量和神经元数量小). 该模型并不具有实际应用价值.\n",
    "&emsp;&emsp;分类效果图和损失曲线反映了模型学习的实时状态, 两者在反映模型学习情况上相互补充, 我们可以根据两者及时地调整模型.  \n",
    "&emsp;&emsp;若损失没有降到 0.01 以下, 说明模型拟合能力不足(在该次实验中几乎不会出现), 从数据集和模型本身来看, 有以下几点原因:\n",
    "1. 模型过于简单\n",
    "2. 特征工程不足\n",
    "3. 训练时间不足\n",
    "4. 数据量不足\n",
    "5. 正则化过度\n",
    "6. 学习率设置不当\n",
    "7. 数据质量问题\n",
    "8. 优化算法选择不当\n",
    "\n",
    "&emsp;&emsp;如果该模型真的出现了这个问题, 最可能的是由于深度模型只能得到局部最优解, 而不是全局最优解, 随机参数初始化过程导致了这个问题.  \n",
    "&emsp;&emsp;以下复现了网站上的代码, 其中达到要求(损失降到 0.01 以下)实测共训练约 330 轮, 约为网站实测值(846轮)的 $\\frac{1}{2}$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8210103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机生成数据, 内圆和外圆各 200 个点\n",
    "X, y = make_circles(400)\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# 定义用于该问题的数据集类\n",
    "class CircleDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return X[index], y[index]\n",
    "\n",
    "# 初始化数据集\n",
    "circle_dataset = CircleDataset(X, y)\n",
    "train_dataset, test_dataset = random_split(circle_dataset, [200, 200])\n",
    "# 初始化数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=10)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1358fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建最简单的模型\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 4), nn.Tanh(),\n",
    "    nn.Linear(4, 4), nn.Tanh(),\n",
    "    nn.Linear(4, 2)\n",
    ").to(device)\n",
    "# 定义损失函数为交叉熵损失\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# 定义优化器为随机梯度下降\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "837d4d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_process(dataloader, model, loss_fn, optimizer):\n",
    "    # 设置模型为训练模式\n",
    "    model.train()\n",
    "    # 初始化训练损失\n",
    "    train_loss = 0\n",
    "    # 遍历数据集\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # 将数据移动到训练硬件上\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # 使用模型获取预测值并计算损失\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        train_loss += loss.item()\n",
    "        # 反向传播\n",
    "        loss.backward()  # 计算梯度\n",
    "        optimizer.step()  # 更新参数\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "    # 返回该次的平均损失\n",
    "    return train_loss / len(dataloader)\n",
    "\n",
    "def test_process(dataloader, model, loss_fn):\n",
    "    # 设置模型为评估模式\n",
    "    model.eval()\n",
    "    # 初始化测试损失和正确数\n",
    "    test_loss, correct = 0, 0\n",
    "    # 不计算梯度\n",
    "    with torch.no_grad():\n",
    "        # 遍历数据集\n",
    "        for X, y in dataloader:\n",
    "            # 将数据移动到训练硬件上\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            # 使用模型获取预测值并计算损失\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            # 计算该批次中的正确数量并累加到 correct 中\n",
    "            correct += (pred.argmax(1) == y) \\\n",
    "                .type(torch.float).sum().item()\n",
    "    return test_loss / len(dataloader), \\\n",
    "        correct / len(dataloader.dataset)\n",
    "\n",
    "def train(\n",
    "    epochs, train_loader, test_loader, model,\n",
    "    loss_fn, optimizer, shutdown=False, print_flag=True\n",
    "):\n",
    "    for t in range(epochs):\n",
    "        train_loss = train_process(\n",
    "            train_loader, model, loss_fn, optimizer\n",
    "        )\n",
    "        test_loss, test_acc = test_process(test_loader, model, loss_fn)\n",
    "        if (t % 10 == 0) and print_flag:\n",
    "            print(\n",
    "                f\"epoch {t}, train loss: {train_loss:.4f}, \"\n",
    "                f\"test loss: {test_loss:.4f}, test acc: {test_acc:.4f}\"\n",
    "            )\n",
    "        if shutdown and test_loss < 0.1:\n",
    "            return train_loss, test_loss, t + 1\n",
    "    return train_loss, test_loss, epochs\n",
    "\n",
    "# 以下为运行该次试验的代码, 需要运行时请取消注释\n",
    "# train(350, train_loader, test_loader, model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a660627f",
   "metadata": {},
   "source": [
    "### 探索学习率对训练速度的影响\n",
    "| 实验序号 | 学习率 | 测试损失达到 0.01 时的 epoch 数 |\n",
    "| :-: | :-: | :-: |\n",
    "| 1 | 0.003 | 约 5500 |\n",
    "| 2 | 0.03 | 846 |\n",
    "| 3 | 0.1 | 127 |\n",
    "| 4 | 1 | (模型无法稳定) |\n",
    "\n",
    "&emsp;&emsp;从表中可以看出, 学习率与训练所需轮数大致成反比, 但学习率过高会导致模型无法收敛: 损失曲线一直在波动, 无法平稳, 分类效果比较差.  \n",
    "&emsp;&emsp;这说明模型的学习率设置不合理或者 Batch 大小不合理, 不能很好地匹配给定的学习率.  \n",
    "&emsp;&emsp;然而学习率不能太小, 这会导致模型需要很多轮才能收敛, 进而去拟合数据.  \n",
    "&emsp;&emsp;以下是寻找最好学习率的代码, 若到 1500 轮测试损失都不能小于 0.01, 则模型被认为不能及时收敛, 仅探讨学习率区间 0.01-0.20, 运行结果为 0.11-0.17 为比较好的学习率:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5d48a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lr():\n",
    "    for i in range(20):\n",
    "        lr = (i+1)*0.01\n",
    "        \n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        model = nn.Sequential(\n",
    "            nn.Linear(2, 4), nn.Tanh(),\n",
    "            nn.Linear(4, 4), nn.Tanh(),\n",
    "            nn.Linear(4, 2)\n",
    "        ).to(device)\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "        \n",
    "        train_loss, test_loss, epochs = train(\n",
    "            1500, train_loader, test_loader,\n",
    "            model, loss_fn, optimizer, True, False\n",
    "        )\n",
    "        print(f\"lr: {lr}, epochs: {epochs}.\")\n",
    "\n",
    "# 以下为运行该次试验的代码, 需要运行时请取消注释\n",
    "# detect_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3278e4be",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "[动手学深度学习(第二版)](动手学深度学习(第二版).pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
